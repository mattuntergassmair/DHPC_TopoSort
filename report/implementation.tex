\section{Efficient parallel implementation}\label{sec:yourmethod}
In this section, the implementation of the parallel algorithm outlined above is presented.
Especially, we show how to ensure load balancing, how to efficiently append nodes to the solution list, how to efficiently decrement and check the parent counter, and a way to circumvent barriers.
\begin{invisible}
 Achtung! Falls Barriers gestrichen werden, streiche and a way to circumvent barriers.
\end{invisible}

\mypar{Parallelization and load balancing}
Parallelization is achieved by distributing the nodes in the front among the threads. We experimented with three implementations.

Firstly, the ``Scatter-Gather'' implementation, represents the front using a linked list of node (pointers). Initially, the source nodes are inserted into this list.
Following an idea described in \cite{bulucc2011parallel}, the nodes in the front are scattered among the threads, such that each thread owns a thread-local list,
that represents its share of the nodes in the front.
Child nodes for the next front are first inserted to another thread-local list.
When the whole front was processed, one thread gathers all thread-local lists and redistributes the new child nodes among the threads.
Redistribution for each front already yields some level of load balancing.

Secondly, the ``Worksteal'' implementation further refines load balancing using a work stealing policy.
If one thread runs out of nodes within a front, it can steal nodes from another thread that has not finished yet.

Thirdly, the ``Node-Lookup'' implementation represents the front using a array of boolean flags, as used in the context of BFS in \cite{agarwal2010scalable} or \cite{beamer2013direction}. The size of the bitset is equal to the number of nodes.
The last parent visiting a child node sets the child nodes' flag to true. Parallelization is then enabled by parallelizing the loop over the bitset.
Load balancing is conveniently achieved using a dynamic scheduler.
Notice that we cannot use a space-efficient bitset, because is not thread-safe.

\mypar{Appending to the solution list}
%All nodes in the current front have already been visited by all their parent nodes. % This is actually an invariant, but never mind.
%This is ensured by admitting only those child nodes to the next front, for which the current node is the last visiting parent node. % Maybe belongs to algorithm description
Nodes can be added to the global solution list, if they are in the current front.
The order among the nodes on one front does not matter for the topological sorting,
because one node cannot be a parent of another node in the current front since all nodes in the current front have been visited by all of their parent nodes, 
As a consequence, the nodes can be appended to the solution concurrently without any restrictions on the order.
Still, the solution list has to be locked for every appending of a node, which is not optimal.

The optimization that we propose here is simple: Every thread first inserts the nodes in a thread-local list and then appends the whole local list to the solution list.
Thereby, each thread grabs the lock only once per front and not for every node individually.
For lists, appending another list can be done in constant time.

\mypar{Decrementing and checking the parent counter}
In the parallel algorithm, every node has a parent counter that is initialized with the number of parent nodes.
As explained before, a node may only be inserted if all its parents have visited it.
Therefore, each parent has to decrement the parent counter to mark its visit and it has to check whether the parent counter is zero, i.e. whether it is the last visiting parent.
Na{\"i}vely, the decrement and the check have to be locked together, in order to avoid race conditions on the counter on the one hand, and in order to ensure that only one thread may return true on the other hand. 
However, a closer examination reveals that these requirements can be met by using atomic operations.

\begin{listing}
 \SetKw{KwRet}{Return}
 \SetKw{KwBool}{Bool}
 \SetKw{KwInt}{Integer}
 \SetKwProg{Fn}{Function}{}{}
  \KwInt parentCounter\;
  \tcp{initialized with number of parent nodes}
  \KwBool token = false\;
  \Fn{decrementAndCheckParentCounter{}} {
    AtomicDecrement(parentCounter)\;
    \KwBool swapped = false\;
    \If{parentCounter == 0}{
      swapped = AtomicCompareAndSwap(token, false, true)\;
    }
    \KwRet swapped;
  }
 \caption{Efficiently decrementing and checking the parent counter using atomic operations.}
 \label{lst:parentCounter}
\end{listing}

Listing \ref{lst:parentCounter} shows the implementation using two separate atomic operations. Multiple threads may in fact decrement the counter before the function returns.
However the atomic compare-and-swap ensures that only one thread can return true. This is important if the current front is implemented as a list.
In this case, the child node would be inserted twice, if multiple threads returned true, which is wrong.
If the front is implemented as an array of flags, the compare-and-swap is in fact not necessary, because it makes no difference if multiple threads set the flag.

\mypar{Barrier-free implementation}
Barriers are used to process the nodes in a front-by-front fashion.
Each front is finished with a barrier, either explicitly, if the front was implemented with a list, or implicitly by a for-loop, if the front was implemented using a bitset.

If barriers are given up, it is no longer certain that all threads work on nodes of the same front.
Some threads may already work on nodes of the next front, while other threads are still working on the previous front.

A priori, this is not a problem, because in any case, a node is only appended to the solution list if all its parents have visited it, regardless of which front its parents belonged to.
However, it is not possible to temporarily store a node in a thread-local list and defer the appending to the solution list, as suggested earlier.
In this case, it would be possible that a node was appended to the solution list, while its parent node has only been appended to a thread-local list, but not yet to the solution list, leading to an invalid result.

Hence, avoiding barriers seems to be a trade-off between the cost of barriers and the cost of locking the solution list for every node.

\begin{invisible}
Hmm... we could defer decrementing the parent counter and inserting the child node until the local list is appended to the solution list. That means, that we have to touch all nodes twice
Somewhere, we need to mention that we are working with an adjacency list.
\end{invisible}