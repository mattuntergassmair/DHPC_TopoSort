
\section{Algorithm}\label{sec:background}
%TODO: Johannes

 In this section, we define the topological sort problem and contrast it to Breadth-First-Search (BFS) and Depth-First-Search (DFS).
 Furthermore, we introduce the basics of the parallel algorithm we use.
 \\
 

\mypar{Topological sorting}
 A directed acyclic graph (DAG) describes a partial order. A topological sorting is a total order on a DAG. Let $G = (V,E)$ be a DAG where $V$ is the set of vertices and $E$ is the set of edges. Formally a topological sorting is a function $ord: V \longrightarrow \{1,...,n\}$ where $n = |V|$ such that $\forall (v,w) \in E: ord(v) < ord(w)$ \cite[Chapter~9.1]{ottmann2012algorithmen}.
\begin{invisible}
Herausfinden, ob ord(v) < ord (w) oder $\leq$. Citation! Widmayer?
\end{invisible}

Figure \ref{fig:ts-example} shows a DAG with a corresponding topological sorting: A,I,F,B,E,D,H,G,C. Even though every DAG has at least one topological sorting, in general there are many different topological sortings for the same graph.

\begin{figure}[!hbp]
 \centering
  \begin{tikzpicture}[->,>=stealth',auto,node distance=1cm,
                    thick,main
                    node/.style={circle,draw,font=\sffamily\scriptsize},text node/.style={draw=none,font=\sffamily\tiny}]

  \node[main node] (1) [draw=black!80,text=black!80] {A};
  \node[main node] (3) [right of=1, node distance=1.2cm]{B};
  \node[main node] (7) [below of=3, node distance=1.2cm] {E};
  \node[main node] (4) [left of=7, node distance=1.2cm] {D};
  \node[main node] (5) [below of=7, node distance=1.2cm] {H};
  \node[main node] (6) [left of=4, node distance=1.2cm] {C};
  \node[main node] (8) [left of=5, node distance=1.2cm] {G};
  \node[main node] (9) [below of=8, node distance=1.2cm] {I};
  \node[main node] (2) [left of=8, node distance=1.2cm] {F};


  \path[every node/.style={font=\sffamily\small}]
    (1) edge (3)
    (3) edge (7)
    (7) edge (4)
    (4) edge (6)
    (7) edge (5)
    (5) edge (8)
    (8) edge (6)
    (9) edge (5)
    (9) edge (2)
    (2) edge (8)
    ;
\end{tikzpicture}

\caption{Example DAG where A,I,F,B,E,D,H,G,C is one possible topological sorting}
\label{fig:ts-example}
\end{figure}

Topological sortings can be  used to schedule tasks based on their dependencies. Every vertex represents a task and the edges represent the relation between the tasks.

Although the results of the breadth-first-search (BFS) algorithm seem to be similar to topological sortings, they are not equivalent. The difference between the results of BFS and a topological sorting is, that a topological sorting is a total order with respect to the partial order represented by the input graph. In contrast, the traversal sequence of a BFS (and DFS) generally don’t correspond to a total order induced by a DAG. A simple example is shown in figure \ref{fig:diff-bfs}. The visiting sequence A,C,B is valid in BFS but is not a topological sorting. The only valid topological sorting for the example graph is A,B,C.


\begin{figure}[!hbp]
\centering
 
  \begin{tikzpicture}[->,>=stealth',auto,node distance=1cm,
                    thick,main
                    node/.style={circle,draw,font=\sffamily\scriptsize},text node/.style={draw=none,font=\sffamily\tiny}]

  \node[main node] (1) [draw=black!80,text=black!80] {A};
  \node[main node] (2) [below right of=1, node distance=1.2cm]{B};
  \node[main node] (3) [below of=1, node distance=1.2cm] {C};
 

  \path[every node/.style={font=\sffamily\small}]
    (1) edge (2)
    (2) edge (3)
    (1) edge (3)
    ;
\end{tikzpicture}

\caption{A,C,B is a valid sequence in breadth-first-search (BFS) and depth-first-search (DFS) but not a topological sorting}
\label{fig:diff-bfs}
\end{figure}

A sequential algorithm yielding a topological sorting has been suggested by Kahn \cite{kahn1962topological}. Another algorithm has been published by Tarjan  \cite{tarjan1976edge} and is based on a DFS with backtracking. Topological sorting has an asymptotic complexity of $\mathcal{O}(|V|+|E|)$ \cite[Chapter~22.4]{cormen2001introduction}. 

 \mypar{Parallel algorithm}
 In 1983 M. C. Er \cite{er1983parallel} came up with a parallel approach to retrieve a topological sorting. The algorithm works in 5 steps:
 \begin{enumerate}
        \item Build the graph from the given partial order (optional if the problem is already stated as a graph).
        \item Add a special node value to every node and initialize it to zero
        \item Visit all source nodes (nodes with an indegree of zero) and set their node values to one.
        \item Start from all source nodes in parallel and proceed for all successor nodes as follows: Let $N_p$ be the node value of the current source node and $N_s$ the node value of the currently observed successor node. Then the algorithm checks if $N_s \leq N_p$ and sets the value of the successor to $N_p + 1$, if so. This step is iterated until there are no further successor nodes. 
        \item List all the nodes in ascending order of node values.
 \end{enumerate}

To avoid a race condition by concurrent writes to a node’s value, M. C. Er proposes a synchronization after every step. Therefore, any two threads would write the same number to a node’s value, because the barrier ensures that all threads are in the same step. This comes at the price of a lower performance. Node values might be rewritten by multiple threads that "follow" each other. For example, in figure \ref{fig:ts-example}, node H, G and C could receive the values 2,3,4 initially, but would eventually be overwritten with the values 4,5,6


The asymptotic parallel runtime of the above algorithm is described by M. C. Er as $\mathcal{O}(D_{max})$, where $D_{max}$ is defined as the maximum distance between a source node and a sink node. This runtime is hard to achieve in practice if one implements step 5 of the algorithm via sorting the nodes with respect to their values. It is not mentioned by M. C. Er how to create the result list of step 5.


\mypar{Improvements}
We propose not to use node values, but to directly put the node into the solution list. This avoids sorting the nodes by their value at the end. Also the barriers are not necessary anymore. However, it must be made sure that no node is written more than once to the result list and race conditions while writing to the solution list must be avoided.

Furthermore, we introduce a parent counter to address the problem of several processes following the same path. The parent counter is initialized to the number of parent nodes. During the algorithm each thread arriving at a node will decrease the counter by one. It will only process the node if the parent counter is zero. Thus a node will be processed only by the last arriving thread. It has to be taken care of the race condition while updating the parent counter.



 
 
 
 \begin{invisible}
 % Serial TS
 \mypar{Topological sorting}
 \begin{itemize}
  \item What is topological sort, difference to BFS
  \item Input: A set of dependencies (aka partial orders) of the form A $\rightarrow$ B ``A must come before B''
  \item Output: A sequence (aka total order) containing all nodes exactly once. All partial orders must be kept.
  \item Solution not unique
  \item Minimal Example: A->B, A->C, B->C. Valid BFS traversal order: A, C, B. Invalid for TS.
  \item TS can (serially) be solved with Kahn's algorithm \cite{kahn1962topological} or DFS and Backpropagation (Tarjan \cite{tarjan1976edge}). % See Wikipedia
        Note that TS is not equivalent to DFS, e.g. for A->B, B->C, A->D, D->E, DFS and Backpropagation yields A, B, C, D, E, but another valid TS is A, B, D, C, E
  \item Asymptotic runtime: O(|V| + |E|)
As an aside, don't talk about "the complexity of the algorithm.'' It's incorrect,
problems have a complexity, not algorithms.  
 \end{itemize}

 % Multithreaded TS
 \mypar{Parallel algorithm}
 \begin{itemize}
  \item Short overview over algorithm of MC Er
  \item Parallelization over child nodes
  \item His idea with barrier in each step such that even if the index is written by multiple threads, they write the same number => Avoid race condition at writing the index
  \item Our idea: Instead of writing an index, directly write to solution list. As a consequence, we have to make sure that node is written to solution only once. And of course there is a race condition on writing to solution list.
  \item Our idea: First, count (in parallel) how many parents each node has. Each time a node is visited, decrement counter and only write to solution if counter is zero. Of course, there is a race condition on the parent counter.
  \item 3 synchronization points (that is, bottlenecks): 1. Barrier after each level, 2. Lock solution list for appending new nodes, 3. Lock parent counter for decrementing it and checking if it is zero.
  \item Cost
 \end{itemize}

 
\end{invisible}